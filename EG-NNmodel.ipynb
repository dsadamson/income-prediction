{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf #numpy needs to be 1.23 or earlier in order for tf to import correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the spark dataframe df a pandas dataframe\n",
    "df = pd.read_csv(\"income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23149 entries, 0 to 23148\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             23149 non-null  int64 \n",
      " 1   workclass       23149 non-null  object\n",
      " 2   education       23149 non-null  object\n",
      " 3   education_num   23149 non-null  int64 \n",
      " 4   marital_status  23149 non-null  object\n",
      " 5   occupation      23149 non-null  object\n",
      " 6   relationship    23149 non-null  object\n",
      " 7   race            23149 non-null  object\n",
      " 8   sex             23149 non-null  object\n",
      " 9   hours_per_week  23149 non-null  int64 \n",
      " 10  native_country  23149 non-null  object\n",
      " 11  income          23149 non-null  object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df[[\"age\", \"hours_per_week\"]]\n",
    "df_obj = df.drop([\"age\", \"education_num\", \"hours_per_week\"], axis = 1)\n",
    "df_obj = df_obj.astype(str)\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df_obj))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names_out()\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "df = df_num.merge(encode_df,left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out our variables\n",
    "y= df[[\"income_>50K\"]]\n",
    "X= df.drop(['income_<=50K', 'income_>50K'], axis = 1)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scale the data\n",
    "X_scaled = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 25)                2500      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 12)                312       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2897 (11.32 KB)\n",
      "Trainable params: 2897 (11.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 25\n",
    "hidden_nodes_layer2 = 12\n",
    "hidden_nodes_layer3 = 6\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "543/543 [==============================] - 1s 731us/step - loss: 0.4207 - accuracy: 0.7899\n",
      "Epoch 2/50\n",
      "543/543 [==============================] - 0s 708us/step - loss: 0.3719 - accuracy: 0.8276\n",
      "Epoch 3/50\n",
      "543/543 [==============================] - 0s 716us/step - loss: 0.3561 - accuracy: 0.8319\n",
      "Epoch 4/50\n",
      "543/543 [==============================] - 0s 733us/step - loss: 0.3481 - accuracy: 0.8343\n",
      "Epoch 5/50\n",
      "543/543 [==============================] - 0s 696us/step - loss: 0.3428 - accuracy: 0.8369\n",
      "Epoch 6/50\n",
      "543/543 [==============================] - 0s 738us/step - loss: 0.3389 - accuracy: 0.8387\n",
      "Epoch 7/50\n",
      "543/543 [==============================] - 0s 736us/step - loss: 0.3360 - accuracy: 0.8407\n",
      "Epoch 8/50\n",
      "543/543 [==============================] - 0s 771us/step - loss: 0.3337 - accuracy: 0.8403\n",
      "Epoch 9/50\n",
      "543/543 [==============================] - 0s 733us/step - loss: 0.3310 - accuracy: 0.8414\n",
      "Epoch 10/50\n",
      "543/543 [==============================] - 0s 719us/step - loss: 0.3281 - accuracy: 0.8432\n",
      "Epoch 11/50\n",
      "543/543 [==============================] - 0s 728us/step - loss: 0.3267 - accuracy: 0.8433\n",
      "Epoch 12/50\n",
      "543/543 [==============================] - 0s 723us/step - loss: 0.3250 - accuracy: 0.8448\n",
      "Epoch 13/50\n",
      "543/543 [==============================] - 0s 741us/step - loss: 0.3228 - accuracy: 0.8463\n",
      "Epoch 14/50\n",
      "543/543 [==============================] - 0s 711us/step - loss: 0.3209 - accuracy: 0.8473\n",
      "Epoch 15/50\n",
      "543/543 [==============================] - 0s 762us/step - loss: 0.3198 - accuracy: 0.8487\n",
      "Epoch 16/50\n",
      "543/543 [==============================] - 0s 721us/step - loss: 0.3175 - accuracy: 0.8489\n",
      "Epoch 17/50\n",
      "543/543 [==============================] - 0s 719us/step - loss: 0.3166 - accuracy: 0.8493\n",
      "Epoch 18/50\n",
      "543/543 [==============================] - 0s 760us/step - loss: 0.3152 - accuracy: 0.8496\n",
      "Epoch 19/50\n",
      "543/543 [==============================] - 0s 738us/step - loss: 0.3140 - accuracy: 0.8499\n",
      "Epoch 20/50\n",
      "543/543 [==============================] - 0s 709us/step - loss: 0.3121 - accuracy: 0.8499\n",
      "Epoch 21/50\n",
      "543/543 [==============================] - 0s 715us/step - loss: 0.3114 - accuracy: 0.8528\n",
      "Epoch 22/50\n",
      "543/543 [==============================] - 0s 705us/step - loss: 0.3107 - accuracy: 0.8534\n",
      "Epoch 23/50\n",
      "543/543 [==============================] - 0s 729us/step - loss: 0.3088 - accuracy: 0.8543\n",
      "Epoch 24/50\n",
      "543/543 [==============================] - 0s 712us/step - loss: 0.3081 - accuracy: 0.8533\n",
      "Epoch 25/50\n",
      "543/543 [==============================] - 0s 700us/step - loss: 0.3068 - accuracy: 0.8553\n",
      "Epoch 26/50\n",
      "543/543 [==============================] - 0s 721us/step - loss: 0.3059 - accuracy: 0.8561\n",
      "Epoch 27/50\n",
      "543/543 [==============================] - 0s 722us/step - loss: 0.3052 - accuracy: 0.8551\n",
      "Epoch 28/50\n",
      "543/543 [==============================] - 0s 763us/step - loss: 0.3041 - accuracy: 0.8562\n",
      "Epoch 29/50\n",
      "543/543 [==============================] - 0s 736us/step - loss: 0.3036 - accuracy: 0.8551\n",
      "Epoch 30/50\n",
      "543/543 [==============================] - 0s 750us/step - loss: 0.3026 - accuracy: 0.8558\n",
      "Epoch 31/50\n",
      "543/543 [==============================] - 0s 724us/step - loss: 0.3021 - accuracy: 0.8568\n",
      "Epoch 32/50\n",
      "543/543 [==============================] - 0s 722us/step - loss: 0.3015 - accuracy: 0.8572\n",
      "Epoch 33/50\n",
      "543/543 [==============================] - 0s 713us/step - loss: 0.3001 - accuracy: 0.8566\n",
      "Epoch 34/50\n",
      "543/543 [==============================] - 0s 707us/step - loss: 0.2991 - accuracy: 0.8580\n",
      "Epoch 35/50\n",
      "543/543 [==============================] - 0s 732us/step - loss: 0.2985 - accuracy: 0.8591\n",
      "Epoch 36/50\n",
      "543/543 [==============================] - 0s 714us/step - loss: 0.2977 - accuracy: 0.8587\n",
      "Epoch 37/50\n",
      "543/543 [==============================] - 0s 712us/step - loss: 0.2979 - accuracy: 0.8570\n",
      "Epoch 38/50\n",
      "543/543 [==============================] - 0s 716us/step - loss: 0.2972 - accuracy: 0.8594\n",
      "Epoch 39/50\n",
      "543/543 [==============================] - 0s 705us/step - loss: 0.2958 - accuracy: 0.8595\n",
      "Epoch 40/50\n",
      "543/543 [==============================] - 0s 714us/step - loss: 0.2960 - accuracy: 0.8616\n",
      "Epoch 41/50\n",
      "543/543 [==============================] - 0s 735us/step - loss: 0.2951 - accuracy: 0.8603\n",
      "Epoch 42/50\n",
      "543/543 [==============================] - 0s 716us/step - loss: 0.2958 - accuracy: 0.8605\n",
      "Epoch 43/50\n",
      "543/543 [==============================] - 0s 720us/step - loss: 0.2939 - accuracy: 0.8602\n",
      "Epoch 44/50\n",
      "543/543 [==============================] - 0s 710us/step - loss: 0.2939 - accuracy: 0.8617\n",
      "Epoch 45/50\n",
      "543/543 [==============================] - 0s 724us/step - loss: 0.2929 - accuracy: 0.8607\n",
      "Epoch 46/50\n",
      "543/543 [==============================] - 0s 718us/step - loss: 0.2926 - accuracy: 0.8623\n",
      "Epoch 47/50\n",
      "543/543 [==============================] - 0s 720us/step - loss: 0.2919 - accuracy: 0.8615\n",
      "Epoch 48/50\n",
      "543/543 [==============================] - 0s 740us/step - loss: 0.2914 - accuracy: 0.8615\n",
      "Epoch 49/50\n",
      "543/543 [==============================] - 0s 717us/step - loss: 0.2907 - accuracy: 0.8620\n",
      "Epoch 50/50\n",
      "543/543 [==============================] - 0s 717us/step - loss: 0.2901 - accuracy: 0.8637\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 - 0s - loss: 0.4124 - accuracy: 0.8283 - 195ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4124058187007904, Accuracy: 0.828265368938446\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
