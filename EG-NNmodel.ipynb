{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf #numpy needs to be 1.23 or earlier in order for tf to import correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the spark dataframe df a pandas dataframe\n",
    "df = pd.read_csv(\"income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23149 entries, 0 to 23148\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             23149 non-null  int64 \n",
      " 1   workclass       23149 non-null  object\n",
      " 2   education       23149 non-null  object\n",
      " 3   education_num   23149 non-null  int64 \n",
      " 4   marital_status  23149 non-null  object\n",
      " 5   occupation      23149 non-null  object\n",
      " 6   relationship    23149 non-null  object\n",
      " 7   race            23149 non-null  object\n",
      " 8   sex             23149 non-null  object\n",
      " 9   hours_per_week  23149 non-null  int64 \n",
      " 10  native_country  23149 non-null  object\n",
      " 11  income          23149 non-null  object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df[[\"age\", \"hours_per_week\"]]\n",
    "df_obj = df.drop([\"age\", \"education_num\", \"hours_per_week\"], axis = 1)\n",
    "df_obj = df_obj.astype(str)\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df_obj))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names_out()\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "df = df_num.merge(encode_df,left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out our variables\n",
    "y= df[[\"income_>50K\"]]\n",
    "X= df.drop(['income_<=50K', 'income_>50K'], axis = 1)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scale the data\n",
    "X_scaled = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 25)                2500      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                312       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2897 (11.32 KB)\n",
      "Trainable params: 2897 (11.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 25\n",
    "hidden_nodes_layer2 = 12\n",
    "hidden_nodes_layer3 = 6\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "543/543 [==============================] - 1s 999us/step - loss: 0.4124 - accuracy: 0.7914\n",
      "Epoch 2/50\n",
      "543/543 [==============================] - 1s 997us/step - loss: 0.3598 - accuracy: 0.8289\n",
      "Epoch 3/50\n",
      "543/543 [==============================] - 1s 972us/step - loss: 0.3505 - accuracy: 0.8337\n",
      "Epoch 4/50\n",
      "543/543 [==============================] - 1s 945us/step - loss: 0.3456 - accuracy: 0.8379\n",
      "Epoch 5/50\n",
      "543/543 [==============================] - 1s 981us/step - loss: 0.3422 - accuracy: 0.8393\n",
      "Epoch 6/50\n",
      "543/543 [==============================] - 1s 924us/step - loss: 0.3390 - accuracy: 0.8387\n",
      "Epoch 7/50\n",
      "543/543 [==============================] - 1s 952us/step - loss: 0.3364 - accuracy: 0.8418\n",
      "Epoch 8/50\n",
      "543/543 [==============================] - 1s 938us/step - loss: 0.3336 - accuracy: 0.8425\n",
      "Epoch 9/50\n",
      "543/543 [==============================] - 1s 932us/step - loss: 0.3318 - accuracy: 0.8437\n",
      "Epoch 10/50\n",
      "543/543 [==============================] - 1s 969us/step - loss: 0.3300 - accuracy: 0.8445\n",
      "Epoch 11/50\n",
      "543/543 [==============================] - 0s 919us/step - loss: 0.3286 - accuracy: 0.8453\n",
      "Epoch 12/50\n",
      "543/543 [==============================] - 0s 914us/step - loss: 0.3266 - accuracy: 0.8458\n",
      "Epoch 13/50\n",
      "543/543 [==============================] - 0s 916us/step - loss: 0.3255 - accuracy: 0.8476\n",
      "Epoch 14/50\n",
      "543/543 [==============================] - 1s 920us/step - loss: 0.3228 - accuracy: 0.8487\n",
      "Epoch 15/50\n",
      "543/543 [==============================] - 1s 953us/step - loss: 0.3214 - accuracy: 0.8476\n",
      "Epoch 16/50\n",
      "543/543 [==============================] - 1s 961us/step - loss: 0.3202 - accuracy: 0.8473\n",
      "Epoch 17/50\n",
      "543/543 [==============================] - 1s 930us/step - loss: 0.3192 - accuracy: 0.8509\n",
      "Epoch 18/50\n",
      "543/543 [==============================] - 1s 978us/step - loss: 0.3177 - accuracy: 0.8506\n",
      "Epoch 19/50\n",
      "543/543 [==============================] - 1s 963us/step - loss: 0.3156 - accuracy: 0.8521\n",
      "Epoch 20/50\n",
      "543/543 [==============================] - 1s 959us/step - loss: 0.3158 - accuracy: 0.8499\n",
      "Epoch 21/50\n",
      "543/543 [==============================] - 1s 985us/step - loss: 0.3139 - accuracy: 0.8509\n",
      "Epoch 22/50\n",
      "543/543 [==============================] - 1s 1ms/step - loss: 0.3126 - accuracy: 0.8519\n",
      "Epoch 23/50\n",
      "543/543 [==============================] - 1s 964us/step - loss: 0.3115 - accuracy: 0.8531\n",
      "Epoch 24/50\n",
      "543/543 [==============================] - 1s 920us/step - loss: 0.3098 - accuracy: 0.8538\n",
      "Epoch 25/50\n",
      "543/543 [==============================] - 1s 970us/step - loss: 0.3091 - accuracy: 0.8543\n",
      "Epoch 26/50\n",
      "543/543 [==============================] - 1s 944us/step - loss: 0.3081 - accuracy: 0.8537\n",
      "Epoch 27/50\n",
      "543/543 [==============================] - 1s 967us/step - loss: 0.3070 - accuracy: 0.8537\n",
      "Epoch 28/50\n",
      "543/543 [==============================] - 0s 913us/step - loss: 0.3057 - accuracy: 0.8554\n",
      "Epoch 29/50\n",
      "543/543 [==============================] - 0s 916us/step - loss: 0.3050 - accuracy: 0.8567\n",
      "Epoch 30/50\n",
      "543/543 [==============================] - 0s 900us/step - loss: 0.3041 - accuracy: 0.8560\n",
      "Epoch 31/50\n",
      "543/543 [==============================] - 1s 946us/step - loss: 0.3034 - accuracy: 0.8582\n",
      "Epoch 32/50\n",
      "543/543 [==============================] - 1s 956us/step - loss: 0.3019 - accuracy: 0.8584\n",
      "Epoch 33/50\n",
      "543/543 [==============================] - 0s 913us/step - loss: 0.3017 - accuracy: 0.8577\n",
      "Epoch 34/50\n",
      "543/543 [==============================] - 0s 905us/step - loss: 0.3006 - accuracy: 0.8565\n",
      "Epoch 35/50\n",
      "543/543 [==============================] - 0s 916us/step - loss: 0.3002 - accuracy: 0.8573\n",
      "Epoch 36/50\n",
      "543/543 [==============================] - 0s 913us/step - loss: 0.2986 - accuracy: 0.8598\n",
      "Epoch 37/50\n",
      "543/543 [==============================] - 1s 952us/step - loss: 0.2993 - accuracy: 0.8588\n",
      "Epoch 38/50\n",
      "543/543 [==============================] - 1s 940us/step - loss: 0.2979 - accuracy: 0.8602\n",
      "Epoch 39/50\n",
      "543/543 [==============================] - 1s 932us/step - loss: 0.2976 - accuracy: 0.8597\n",
      "Epoch 40/50\n",
      "543/543 [==============================] - 1s 919us/step - loss: 0.2963 - accuracy: 0.8608\n",
      "Epoch 41/50\n",
      "543/543 [==============================] - 0s 917us/step - loss: 0.2959 - accuracy: 0.8604\n",
      "Epoch 42/50\n",
      "543/543 [==============================] - 1s 948us/step - loss: 0.2945 - accuracy: 0.8602\n",
      "Epoch 43/50\n",
      "543/543 [==============================] - 1s 1ms/step - loss: 0.2946 - accuracy: 0.8601\n",
      "Epoch 44/50\n",
      "543/543 [==============================] - 1s 929us/step - loss: 0.2949 - accuracy: 0.8608\n",
      "Epoch 45/50\n",
      "543/543 [==============================] - 1s 921us/step - loss: 0.2929 - accuracy: 0.8623\n",
      "Epoch 46/50\n",
      "543/543 [==============================] - 1s 925us/step - loss: 0.2936 - accuracy: 0.8610\n",
      "Epoch 47/50\n",
      "543/543 [==============================] - 1s 960us/step - loss: 0.2920 - accuracy: 0.8634\n",
      "Epoch 48/50\n",
      "543/543 [==============================] - 0s 908us/step - loss: 0.2915 - accuracy: 0.8633\n",
      "Epoch 49/50\n",
      "543/543 [==============================] - 1s 930us/step - loss: 0.2917 - accuracy: 0.8625\n",
      "Epoch 50/50\n",
      "543/543 [==============================] - 1s 920us/step - loss: 0.2900 - accuracy: 0.8615\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 - 0s - loss: 0.3986 - accuracy: 0.8293 - 243ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.39858028292655945, Accuracy: 0.8293020129203796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(nn, open('model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
