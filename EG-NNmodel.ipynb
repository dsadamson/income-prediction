{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf #numpy needs to be 1.23 or earlier in order for tf to import correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the spark dataframe df a pandas dataframe\n",
    "income = pd.read_csv(\"income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             25000 non-null  int64 \n",
      " 1   workclass       23571 non-null  object\n",
      " 2   education       25000 non-null  object\n",
      " 3   education_num   25000 non-null  int64 \n",
      " 4   marital_status  25000 non-null  object\n",
      " 5   occupation      23566 non-null  object\n",
      " 6   relationship    25000 non-null  object\n",
      " 7   race            25000 non-null  object\n",
      " 8   sex             25000 non-null  object\n",
      " 9   hours_per_week  25000 non-null  int64 \n",
      " 10  native_country  24563 non-null  object\n",
      " 11  income          25000 non-null  object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "income.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_cat = income.dtypes[income.dtypes == 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass          8\n",
       "education         16\n",
       "marital_status     7\n",
       "occupation        14\n",
       "relationship       6\n",
       "race               5\n",
       "sex                2\n",
       "native_country    40\n",
       "income             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the number of unique values in each column\n",
    "income[income_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "      <th>workclass_nan</th>\n",
       "      <th>education_10th</th>\n",
       "      <th>...</th>\n",
       "      <th>native_country_South</th>\n",
       "      <th>native_country_Taiwan</th>\n",
       "      <th>native_country_Thailand</th>\n",
       "      <th>native_country_Trinadad&amp;Tobago</th>\n",
       "      <th>native_country_United-States</th>\n",
       "      <th>native_country_Vietnam</th>\n",
       "      <th>native_country_Yugoslavia</th>\n",
       "      <th>native_country_nan</th>\n",
       "      <th>income_&lt;=50K</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   workclass_Federal-gov  workclass_Local-gov  workclass_Never-worked  \\\n",
       "0                    0.0                  0.0                     0.0   \n",
       "1                    0.0                  0.0                     0.0   \n",
       "2                    0.0                  0.0                     0.0   \n",
       "3                    0.0                  0.0                     0.0   \n",
       "4                    0.0                  0.0                     0.0   \n",
       "\n",
       "   workclass_Private  workclass_Self-emp-inc  workclass_Self-emp-not-inc  \\\n",
       "0                0.0                     0.0                         1.0   \n",
       "1                1.0                     0.0                         0.0   \n",
       "2                1.0                     0.0                         0.0   \n",
       "3                1.0                     0.0                         0.0   \n",
       "4                0.0                     0.0                         0.0   \n",
       "\n",
       "   workclass_State-gov  workclass_Without-pay  workclass_nan  education_10th  \\\n",
       "0                  0.0                    0.0            0.0             0.0   \n",
       "1                  0.0                    0.0            0.0             0.0   \n",
       "2                  0.0                    0.0            0.0             0.0   \n",
       "3                  0.0                    0.0            0.0             0.0   \n",
       "4                  0.0                    0.0            1.0             0.0   \n",
       "\n",
       "   ...  native_country_South  native_country_Taiwan  native_country_Thailand  \\\n",
       "0  ...                   0.0                    0.0                      0.0   \n",
       "1  ...                   0.0                    0.0                      0.0   \n",
       "2  ...                   0.0                    0.0                      0.0   \n",
       "3  ...                   0.0                    0.0                      0.0   \n",
       "4  ...                   0.0                    0.0                      0.0   \n",
       "\n",
       "   native_country_Trinadad&Tobago  native_country_United-States  \\\n",
       "0                             0.0                           1.0   \n",
       "1                             0.0                           1.0   \n",
       "2                             0.0                           1.0   \n",
       "3                             0.0                           1.0   \n",
       "4                             0.0                           0.0   \n",
       "\n",
       "   native_country_Vietnam  native_country_Yugoslavia  native_country_nan  \\\n",
       "0                     0.0                        0.0                 0.0   \n",
       "1                     0.0                        0.0                 0.0   \n",
       "2                     0.0                        0.0                 0.0   \n",
       "3                     0.0                        0.0                 0.0   \n",
       "4                     0.0                        0.0                 0.0   \n",
       "\n",
       "   income_<=50K  income_>50K  \n",
       "0           0.0          1.0  \n",
       "1           1.0          0.0  \n",
       "2           0.0          1.0  \n",
       "3           0.0          1.0  \n",
       "4           1.0          0.0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(income[income_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names_out(income_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native_country_South</th>\n",
       "      <th>native_country_Taiwan</th>\n",
       "      <th>native_country_Thailand</th>\n",
       "      <th>native_country_Trinadad&amp;Tobago</th>\n",
       "      <th>native_country_United-States</th>\n",
       "      <th>native_country_Vietnam</th>\n",
       "      <th>native_country_Yugoslavia</th>\n",
       "      <th>native_country_nan</th>\n",
       "      <th>income_&lt;=50K</th>\n",
       "      <th>income_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  education_num  hours_per_week  workclass_Federal-gov  \\\n",
       "0   40             15              70                    0.0   \n",
       "1   30              9              40                    0.0   \n",
       "2   46             10              40                    0.0   \n",
       "3   32             11              60                    0.0   \n",
       "4   54              1              40                    0.0   \n",
       "\n",
       "   workclass_Local-gov  workclass_Never-worked  workclass_Private  \\\n",
       "0                  0.0                     0.0                0.0   \n",
       "1                  0.0                     0.0                1.0   \n",
       "2                  0.0                     0.0                1.0   \n",
       "3                  0.0                     0.0                1.0   \n",
       "4                  0.0                     0.0                0.0   \n",
       "\n",
       "   workclass_Self-emp-inc  workclass_Self-emp-not-inc  workclass_State-gov  \\\n",
       "0                     0.0                         1.0                  0.0   \n",
       "1                     0.0                         0.0                  0.0   \n",
       "2                     0.0                         0.0                  0.0   \n",
       "3                     0.0                         0.0                  0.0   \n",
       "4                     0.0                         0.0                  0.0   \n",
       "\n",
       "   ...  native_country_South  native_country_Taiwan  native_country_Thailand  \\\n",
       "0  ...                   0.0                    0.0                      0.0   \n",
       "1  ...                   0.0                    0.0                      0.0   \n",
       "2  ...                   0.0                    0.0                      0.0   \n",
       "3  ...                   0.0                    0.0                      0.0   \n",
       "4  ...                   0.0                    0.0                      0.0   \n",
       "\n",
       "   native_country_Trinadad&Tobago  native_country_United-States  \\\n",
       "0                             0.0                           1.0   \n",
       "1                             0.0                           1.0   \n",
       "2                             0.0                           1.0   \n",
       "3                             0.0                           1.0   \n",
       "4                             0.0                           0.0   \n",
       "\n",
       "   native_country_Vietnam  native_country_Yugoslavia  native_country_nan  \\\n",
       "0                     0.0                        0.0                 0.0   \n",
       "1                     0.0                        0.0                 0.0   \n",
       "2                     0.0                        0.0                 0.0   \n",
       "3                     0.0                        0.0                 0.0   \n",
       "4                     0.0                        0.0                 0.0   \n",
       "\n",
       "   income_<=50K  income_>50K  \n",
       "0           0.0          1.0  \n",
       "1           1.0          0.0  \n",
       "2           0.0          1.0  \n",
       "3           0.0          1.0  \n",
       "4           1.0          0.0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "income = income.merge(encode_df,left_index=True, right_index=True)\n",
    "income = income.drop(income_cat,axis=1)\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop income_>50K because there are 2 income columns\n",
    "income.drop(['income_<=50K'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = income[\"income_>50K\"].values #target is a binary 1 or 0 response\n",
    "X = income.drop([\"income_>50K\"], axis=1).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scale the data\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 25)                2625      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                312       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3022 (11.80 KB)\n",
      "Trainable params: 3022 (11.80 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 25\n",
    "hidden_nodes_layer2 = 12\n",
    "hidden_nodes_layer3 = 6\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - 1s 731us/step - loss: 0.4392 - accuracy: 0.7795\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 0s 743us/step - loss: 0.3485 - accuracy: 0.8346\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 0s 715us/step - loss: 0.3410 - accuracy: 0.8397\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 0s 733us/step - loss: 0.3355 - accuracy: 0.8441\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 0s 801us/step - loss: 0.3330 - accuracy: 0.8468\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 0s 759us/step - loss: 0.3292 - accuracy: 0.8473\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 0s 735us/step - loss: 0.3271 - accuracy: 0.8484\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 0s 741us/step - loss: 0.3243 - accuracy: 0.8498\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 0s 747us/step - loss: 0.3226 - accuracy: 0.8516\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 0s 747us/step - loss: 0.3202 - accuracy: 0.8515\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 0s 750us/step - loss: 0.3186 - accuracy: 0.8538\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 0s 748us/step - loss: 0.3164 - accuracy: 0.8533\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 0s 737us/step - loss: 0.3140 - accuracy: 0.8555\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 0s 759us/step - loss: 0.3124 - accuracy: 0.8553\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 0s 767us/step - loss: 0.3110 - accuracy: 0.8565\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 0s 794us/step - loss: 0.3089 - accuracy: 0.8575\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 1s 904us/step - loss: 0.3080 - accuracy: 0.8588\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 0s 841us/step - loss: 0.3064 - accuracy: 0.8587\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 1s 901us/step - loss: 0.3045 - accuracy: 0.8598\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 0s 837us/step - loss: 0.3033 - accuracy: 0.8600\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 0s 818us/step - loss: 0.3014 - accuracy: 0.8609\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 0s 742us/step - loss: 0.3002 - accuracy: 0.8614\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 0s 753us/step - loss: 0.2994 - accuracy: 0.8615\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 0s 731us/step - loss: 0.2983 - accuracy: 0.8618\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 0s 732us/step - loss: 0.2974 - accuracy: 0.8612\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 0s 762us/step - loss: 0.2966 - accuracy: 0.8622\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 0s 729us/step - loss: 0.2956 - accuracy: 0.8637\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 0s 744us/step - loss: 0.2946 - accuracy: 0.8633\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 0s 740us/step - loss: 0.2933 - accuracy: 0.8654\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 0s 745us/step - loss: 0.2927 - accuracy: 0.8655\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 1s 872us/step - loss: 0.2920 - accuracy: 0.8646\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 1s 897us/step - loss: 0.2911 - accuracy: 0.8651\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 1s 876us/step - loss: 0.2905 - accuracy: 0.8663\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 0s 808us/step - loss: 0.2898 - accuracy: 0.8644\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 0s 821us/step - loss: 0.2880 - accuracy: 0.8668\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.2885 - accuracy: 0.8664\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 1s 966us/step - loss: 0.2870 - accuracy: 0.8665\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 0s 801us/step - loss: 0.2859 - accuracy: 0.8661\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 1s 920us/step - loss: 0.2857 - accuracy: 0.8673\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 1s 955us/step - loss: 0.2857 - accuracy: 0.8683\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 1s 970us/step - loss: 0.2843 - accuracy: 0.8685\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 1s 860us/step - loss: 0.2838 - accuracy: 0.8673\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 1s 860us/step - loss: 0.2832 - accuracy: 0.8666\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 1s 884us/step - loss: 0.2821 - accuracy: 0.8688\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - 1s 866us/step - loss: 0.2817 - accuracy: 0.8693\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.2811 - accuracy: 0.8684\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.2805 - accuracy: 0.8682\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - 1s 1ms/step - loss: 0.2799 - accuracy: 0.8689\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - 0s 811us/step - loss: 0.2790 - accuracy: 0.8696\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - 0s 784us/step - loss: 0.2782 - accuracy: 0.8698\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 - 0s - loss: 0.4352 - accuracy: 0.8211 - 192ms/epoch - 978us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.43517643213272095, Accuracy: 0.821120023727417\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
