{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                               33.0\n",
      "hours_per_week                     1.0\n",
      "workclass_Federal-gov              0.0\n",
      "workclass_Local-gov                0.0\n",
      "workclass_Private                  0.0\n",
      "                                  ... \n",
      "native_country_Thailand            0.0\n",
      "native_country_Trinadad&Tobago     0.0\n",
      "native_country_United-States       1.0\n",
      "native_country_Vietnam             0.0\n",
      "native_country_Yugoslavia          0.0\n",
      "Name: 23149, Length: 99, dtype: float64\n",
      "you reached line 35 yay!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m enc \u001b[39m=\u001b[39m OneHotEncoder(sparse_output\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m \u001b[39m# Fit and transform the OneHotEncoder using the categorical variable list\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m encode_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(enc\u001b[39m.\u001b[39;49mfit_transform(df_obj))\n\u001b[0;32m     25\u001b[0m \u001b[39m# Add the encoded variable names to the dataframe\u001b[39;00m\n\u001b[0;32m     26\u001b[0m encode_df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mget_feature_names_out()\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:982\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    972\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    973\u001b[0m         (\n\u001b[0;32m    974\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`sparse` was renamed to `sparse_output` in version 1.2 and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse\n\u001b[1;32m--> 982\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    983\u001b[0m     X,\n\u001b[0;32m    984\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[0;32m    985\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    987\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_drop_idx()\n\u001b[0;32m    988\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features_outs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_n_features_outs()\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:76\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[1;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_infrequent_enabled()\n\u001b[0;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 76\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     77\u001b[0m X_list, n_samples, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(\n\u001b[0;32m     78\u001b[0m     X, force_all_finite\u001b[39m=\u001b[39mforce_all_finite\n\u001b[0;32m     79\u001b[0m )\n\u001b[0;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m n_features\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:440\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[39m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \n\u001b[0;32m    422\u001b[0m \u001b[39m.. versionadded:: 1.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[39m       should set `reset=False`.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m reset:\n\u001b[1;32m--> 440\u001b[0m     feature_names_in \u001b[39m=\u001b[39m _get_feature_names(X)\n\u001b[0;32m    441\u001b[0m     \u001b[39mif\u001b[39;00m feature_names_in \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names_in_ \u001b[39m=\u001b[39m feature_names_in\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:2021\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m   2019\u001b[0m \u001b[39m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[0;32m   2020\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(types) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m types:\n\u001b[1;32m-> 2021\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2022\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names are only supported if all input features have string names, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2023\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut your input has \u001b[39m\u001b[39m{\u001b[39;00mtypes\u001b[39m}\u001b[39;00m\u001b[39m as feature name / column name types. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2024\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2025\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2026\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2027\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdata, or convert them all to a non-string data type.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2028\u001b[0m     )\n\u001b[0;32m   2030\u001b[0m \u001b[39m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(types) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m types[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "#import test.csv\n",
    "test = pd.read_csv('test.csv')\n",
    "data= test.iloc[-1]\n",
    "with open('model.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "print(data)\n",
    "#import income.csv as panda dataframe\n",
    "df = pd.read_csv('income.csv')\n",
    "\n",
    "#drop income\n",
    "df = df.drop(['income'], axis=1)\n",
    "#append data to income.csv\n",
    "df = pd.concat([df, data], ignore_index=True)\n",
    "print(\"you reached line 35 yay!\")\n",
    "\n",
    "df_num = df[[\"age\", \"hours_per_week\"]]\n",
    "df_obj = df.drop([\"age\",\"hours_per_week\"], axis = 1)\n",
    "df_obj = df_obj.astype(str)\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df_obj))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names_out()\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "df = df_num.merge(encode_df,left_index=True, right_index=True)\n",
    "X= df\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scale the data\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "newX = X_scaled[-1]\n",
    "print(newX)\n",
    "print('newX is above')\n",
    "\n",
    "# Make predictions using the model\n",
    "prediction = model.predict(newX)\n",
    "\n",
    "\n",
    "print('prediction is', prediction)\n",
    "# Return the prediction as a JSON response\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
